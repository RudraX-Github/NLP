{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Voice NLP Suite (PRO Edition v4.0 - Dynamic Synthesis & Reporting)\n",
    "Author: AI/ML Engineer (Gemini)\n",
    "Date: 2025-10-10\n",
    "Description: An advanced, integrated suite for capturing, analyzing, and synthesizing voice.\n",
    "             This version introduces user-selectable emotional tones for synthesis and\n",
    "             provides detailed, explanatory analysis reports.\n",
    "\"\"\"\n",
    "# --- Suppress all warnings for a clean, user-friendly output ---\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Core Libraries ---\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import speech_recognition as sr\n",
    "import librosa\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import soundfile as sf # Moved for robust import\n",
    "\n",
    "# --- Optional Visualization & UI Libraries ---\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    VISUALIZATION_ENABLED = True\n",
    "except ImportError:\n",
    "    VISUALIZATION_ENABLED = False\n",
    "\n",
    "try:\n",
    "    from rich.console import Console\n",
    "    from rich.panel import Panel\n",
    "    from rich.prompt import Prompt, Confirm\n",
    "    from rich.table import Table\n",
    "    from rich.live import Live\n",
    "    RICH_UI_ENABLED = True\n",
    "except ImportError:\n",
    "    RICH_UI_ENABLED = False\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from TTS.api import TTS\n",
    "    from TTS.tts.configs.xtts_config import XttsConfig\n",
    "    from TTS.tts.models.xtts import XttsAudioConfig, XttsArgs\n",
    "    from TTS.tts.configs.shared_configs import BaseDatasetConfig, BaseTTSConfig\n",
    "    import parselmouth\n",
    "    from parselmouth.praat import call as praat_call\n",
    "    from langdetect import detect as detect_language\n",
    "    import noisereduce as nr\n",
    "\n",
    "    # NOTE: PyTorch compatibility fix is now handled locally in initialize_tts_model()\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ A required library is missing. Please ensure all dependencies are installed. Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Initialize UI ---\n",
    "if RICH_UI_ENABLED:\n",
    "    console = Console()\n",
    "else:\n",
    "    class FallbackConsole:\n",
    "        def print(self, text): print(text)\n",
    "    console = FallbackConsole()\n",
    "\n",
    "# --- Configuration ---\n",
    "SAMPLE_RATE = 22050\n",
    "INPUT_FILENAME = \"user_voice_input.wav\"\n",
    "CLEANED_FILENAME = \"cleaned_user_voice.wav\"\n",
    "CLONED_FILENAME = \"cloned_voice_output.wav\"\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    console.print(\"[bold bright_yellow]spaCy model 'en_core_web_sm' not found. Downloading...[/bold bright_yellow]\")\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "os.environ['COQUI_TOS_AGREED'] = '1'\n",
    "\n",
    "# --- 1. Voice Capture & Preprocessing ---\n",
    "def record_audio(duration=10):\n",
    "    console.print(f\"\\nðŸŽ™ï¸ [bold bright_cyan]Starting recording for {duration} seconds...[/bold bright_cyan]\")\n",
    "    recording = sd.rec(int(duration * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='int16')\n",
    "    \n",
    "    if RICH_UI_ENABLED:\n",
    "        with Live(console=console, screen=False, auto_refresh=False) as live:\n",
    "            for i in range(duration, 0, -1):\n",
    "                live.update(f\"   [bold yellow]Recording... {i}s remaining[/bold yellow]\", refresh=True)\n",
    "                time.sleep(1)\n",
    "    else:\n",
    "        for i in range(duration, 0, -1):\n",
    "            print(f\"   Recording... {i}s remaining\", end='\\r')\n",
    "            time.sleep(1)\n",
    "        print()\n",
    "\n",
    "    sd.wait()\n",
    "    wav.write(INPUT_FILENAME, SAMPLE_RATE, recording)\n",
    "    console.print(f\"âœ… [bold green]Audio successfully saved to {INPUT_FILENAME}[/bold green]\")\n",
    "    return INPUT_FILENAME\n",
    "\n",
    "def run_preprocessing_menu(input_file, output_file):\n",
    "    console.print(Panel(\"[bold]ðŸ§¹ Optional Audio Preprocessing[/bold]\", style=\"bright_cyan\", title=\"Noise Reduction\"))\n",
    "    if not Confirm.ask(\"[bold]Do you want to apply noise reduction to the recorded audio?[/bold]\"):\n",
    "        console.print(\"[bold yellow]Skipping noise reduction. Using original audio.[/bold yellow]\")\n",
    "        return input_file\n",
    "\n",
    "    prompt_text = (\n",
    "        \"[bold]Choose a noise reduction method:[/bold]\\n\"\n",
    "        \"[1] Soft     - [cyan]Basic filter for minor hiss or hum.[/cyan]\\n\"\n",
    "        \"[2] Moderate - [yellow]Profile-based reduction for steady background noise.[/yellow]\\n\"\n",
    "        \"[3] Robust   - [red]Aggressive vocal isolation for complex environments.[/red]\"\n",
    "    )\n",
    "    console.print(prompt_text)\n",
    "    choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=[\"1\", \"2\", \"3\"], default=\"2\")\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=SAMPLE_RATE)\n",
    "        \n",
    "        if choice == '1': # Soft\n",
    "            console.print(\"[italic]Applying soft noise reduction...[/italic]\")\n",
    "            reduced_noise = nr.reduce_noise(y=y, sr=sr, prop_decrease=0.8)\n",
    "        \n",
    "        elif choice == '2': # Moderate\n",
    "            console.print(\"[italic]Applying moderate (profile-based) noise reduction...[/italic]\")\n",
    "            non_silent = librosa.effects.split(y, top_db=30)\n",
    "            noise_clip = y[0:non_silent[0][0]] if len(non_silent) > 0 and non_silent[0][0] > 0 else y[0:int(sr*0.5)]\n",
    "            reduced_noise = nr.reduce_noise(y=y, y_noise=noise_clip, sr=sr, prop_decrease=0.95)\n",
    "        \n",
    "        elif choice == '3': # Robust\n",
    "            console.print(\"[italic]Applying robust vocal isolation...[/italic]\")\n",
    "            reduced_noise, _ = librosa.effects.hpss(y)\n",
    "\n",
    "        sf.write(output_file, reduced_noise, sr)\n",
    "        console.print(f\"âœ… [bold green]Noise reduction complete. Using cleaned audio.[/bold green]\")\n",
    "        return output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        console.print(f\"âŒ [bold red]Could not perform noise reduction: {e}. Using original audio.[/bold red]\")\n",
    "        return input_file\n",
    "\n",
    "\n",
    "# --- 2. Speech Recognition Engine ---\n",
    "def transcribe_audio(audio_file):\n",
    "    console.print(\"\\nðŸ§  [bold bright_cyan]Transcribing audio with Whisper...[/bold bright_cyan]\")\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.AudioFile(audio_file) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "        text = recognizer.recognize_whisper(audio_data, model=\"base.en\", language=\"english\")\n",
    "        console.print(f\"ðŸ“ [bold green]Transcription:[/bold green] \\\"{text}\\\"\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        console.print(f\"âŒ [bold red]An error occurred during transcription: {e}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "# --- 3. Core Analysis Engine (Fully Implemented) ---\n",
    "class VoiceAnalyzer:\n",
    "    def __init__(self, audio_file, transcribed_text):\n",
    "        if not os.path.exists(audio_file):\n",
    "            raise FileNotFoundError(f\"Audio file not found at {audio_file}\")\n",
    "        self.audio_file = audio_file\n",
    "        self.text = transcribed_text if transcribed_text else \"\"\n",
    "        self.y, self.sr = librosa.load(self.audio_file, sr=SAMPLE_RATE)\n",
    "        self.duration_seconds = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        self.sound = parselmouth.Sound(self.audio_file)\n",
    "\n",
    "    def analyze_acoustic(self):\n",
    "        try:\n",
    "            pitch = praat_call(self.sound, \"To Pitch\", 0.0, 75, 600)\n",
    "            mean_pitch = praat_call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "            formant = praat_call(self.sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 50)\n",
    "            f1_mean = praat_call(formant, \"Get mean\", 1, 0, 0, \"Hertz\")\n",
    "            f2_mean = praat_call(formant, \"Get mean\", 2, 0, 0, \"Hertz\")\n",
    "            rms = librosa.feature.rms(y=self.y)[0]\n",
    "            non_silent_intervals = librosa.effects.split(self.y, top_db=30)\n",
    "            snr = 20 * np.log10(np.mean(rms[non_silent_intervals[0][0]:non_silent_intervals[-1][1]]) / np.mean(rms[:non_silent_intervals[0][0]])) if len(non_silent_intervals) > 1 else 'N/A'\n",
    "\n",
    "            return {\n",
    "                \"Pitch & Tone\": {\"Mean Fundamental Frequency (Hz)\": f\"{mean_pitch:.2f}\"},\n",
    "                \"Formant (Vowel) Analysis\": {\"Mean F1 (Hz)\": f\"{f1_mean:.2f}\", \"Mean F2 (Hz)\": f\"{f2_mean:.2f}\"},\n",
    "                \"Energy & Loudness\": {\"Average Intensity (RMS)\": f\"{np.mean(rms):.4f}\"},\n",
    "                \"Audio Quality\": {\"Voice Segments Detected\": f\"{len(non_silent_intervals)}\", \"Estimated SNR (dB)\": f\"{snr}\" if isinstance(snr, float) else snr}\n",
    "            }\n",
    "        except Exception as e: return {\"Error\": f\"Analysis failed. {e}\"}\n",
    "\n",
    "    def analyze_linguistic(self):\n",
    "        if not self.text: return {\"Error\": \"No text to analyze.\"}\n",
    "        doc = nlp(self.text)\n",
    "        blob = TextBlob(self.text)\n",
    "        intent = \"Informational\"\n",
    "        if any(token.lemma_ in [\"can\", \"what\", \"who\", \"where\", \"when\", \"why\", \"how\"] for token in doc) and \"?\" in self.text: intent = \"Question\"\n",
    "        elif doc and doc[0].pos_ == \"VERB\": intent = \"Command/Imperative\"\n",
    "\n",
    "        return {\n",
    "            \"Transcription\": {\"Full Text\": self.text},\n",
    "            \"Grammatical Analysis\": {\"Part-of-Speech Tags\": [(token.text, token.pos_) for token in doc]},\n",
    "            \"Semantic Content\": {\"Named Entities (NER)\": [(ent.text, ent.label_) for ent in doc.ents] or \"None detected\", \"Keywords\": [chunk.text for chunk in doc.noun_chunks] or \"None detected\"},\n",
    "            \"Sentiment & Intent\": {\"Polarity\": f\"{blob.sentiment.polarity:.2f}\", \"Subjectivity\": f\"{blob.sentiment.subjectivity:.2f}\", \"Inferred Intent\": intent}\n",
    "        }\n",
    "\n",
    "    def analyze_emotional(self):\n",
    "        try:\n",
    "            jitter = \"N/A (Calculation failed)\"; shimmer = \"N/A (Calculation failed)\"; std_dev_pitch_str = \"N/A (Pitch not detected)\"\n",
    "            try:\n",
    "                pitch = praat_call(self.sound, \"To Pitch\", 0.0, 75, 600)\n",
    "                std_dev_pitch = praat_call(pitch, \"Get standard deviation\", 0, 0, \"Hertz\")\n",
    "                std_dev_pitch_str = f\"{std_dev_pitch:.2f}\"\n",
    "            except Exception: pass\n",
    "            try:\n",
    "                point_process = praat_call(self.sound, \"To PointProcess (periodic, cc)\", 75, 600)\n",
    "                if praat_call(point_process, \"Get number of points\") > 1:\n",
    "                    jitter = f\"{praat_call(point_process, 'Get jitter (local)', 0, 0, 0.0001, 0.02, 1.3) * 100:.4f}%\"\n",
    "                    shimmer = f\"{praat_call(point_process, 'Get shimmer (local)', 0, 0, 0.0001, 0.02, 1.3, 1.6) * 100:.4f}%\"\n",
    "                else:\n",
    "                    jitter = \"N/A (Not enough voiced periods)\"; shimmer = \"N/A (Not enough voiced periods)\"\n",
    "            except Exception: pass\n",
    "            return {\n",
    "                \"Prosody & Expressiveness\": {\"Pitch Variation (Std Dev Hz)\": std_dev_pitch_str},\n",
    "                \"Vocal Strain/Stability\": {\"Jitter (Frequency Perturbation)\": jitter, \"Shimmer (Amplitude Perturbation)\": shimmer}\n",
    "            }\n",
    "        except Exception as e: return {\"Error\": f\"A fundamental analysis error occurred. Details: {e}\"}\n",
    "\n",
    "    def analyze_biometric(self):\n",
    "        try:\n",
    "            pitch = praat_call(self.sound, \"To Pitch\", 0.0, 75, 600)\n",
    "            mean_pitch = praat_call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "            gender = \"Undetermined\"\n",
    "            if 85 < mean_pitch < 180: gender = \"Likely Male\"\n",
    "            elif 165 < mean_pitch < 255: gender = \"Likely Female\"\n",
    "            return {\n",
    "                \"Identity Estimation\": {\"Estimated Gender\": f\"{gender} (based on {mean_pitch:.2f} Hz avg pitch)\"},\n",
    "                \"Conceptual\": {\"Speaker ID/Verification\": \"Requires specialized models not included in this suite.\"}\n",
    "            }\n",
    "        except Exception as e: return {\"Error\": f\"Analysis failed. {e}\"}\n",
    "\n",
    "    def analyze_technical(self):\n",
    "        if not self.text: return {\"Error\": \"No text to analyze.\"}\n",
    "        try: language = detect_language(self.text).upper()\n",
    "        except: language = \"Detection failed\"\n",
    "        non_silent_intervals = librosa.effects.split(self.y, top_db=30)\n",
    "        speaking_rate = (len(self.text.split()) / self.duration_seconds) * 60 if self.duration_seconds > 0 else 0\n",
    "        return {\n",
    "            \"Speech Fluency\": {\"Speaking Rate (WPM)\": f\"{speaking_rate:.2f}\", \"Number of Pauses\": max(0, len(non_silent_intervals) - 1)},\n",
    "            \"Content Spotting\": {\"Detected Language\": language}\n",
    "        }\n",
    "\n",
    "# --- 4. Quality & Visualization Modules ---\n",
    "def perform_quality_check(original_file, cloned_file):\n",
    "    console.print(\"\\nðŸ” [bold bright_cyan]Performing automated quality check...[/bold bright_cyan]\")\n",
    "    try:\n",
    "        y_orig, _ = librosa.load(original_file, sr=SAMPLE_RATE)\n",
    "        y_cloned, _ = librosa.load(cloned_file, sr=SAMPLE_RATE)\n",
    "        rms_orig = librosa.feature.rms(y=y_orig)[0]\n",
    "        rms_cloned = librosa.feature.rms(y=y_cloned)[0]\n",
    "        ratio = np.std(rms_cloned) / np.std(rms_orig) if np.std(rms_orig) > 0 else 0\n",
    "        if ratio < 0.6: console.print(f\"âš ï¸ [bold bright_yellow]Quality Warning:[/bold bright_yellow] Synthesized voice has less dynamic range ({ratio:.2f} ratio).\")\n",
    "        else: console.print(f\"âœ… [bold green]Quality Check Passed:[/bold green] Similar dynamic range to original ({ratio:.2f} ratio).\")\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]Could not perform quality check. Error: {e}[/bold red]\")\n",
    "\n",
    "def visualize_and_save_audio(original_file, cloned_file):\n",
    "    if not VISUALIZATION_ENABLED: return\n",
    "    console.print(\"\\nðŸ“Š [bold bright_cyan]Generating voice waveform comparison...[/bold bright_cyan]\")\n",
    "    try:\n",
    "        y_orig, sr_orig = librosa.load(original_file, sr=SAMPLE_RATE)\n",
    "        y_cloned, sr_cloned = librosa.load(cloned_file, sr=SAMPLE_RATE)\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True, sharey=True)\n",
    "        fig.suptitle('Voice Waveform Comparison', fontsize=16, weight='bold')\n",
    "        librosa.display.waveshow(y_orig, sr=sr_orig, ax=axes[0], color='royalblue'); axes[0].set_title(\"Original Recorded Voice\", weight='bold'); axes[0].set_ylabel(\"Amplitude\")\n",
    "        librosa.display.waveshow(y_cloned, sr=sr_cloned, ax=axes[1], color='darkorange'); axes[1].set_title(\"Synthesized (Cloned) Voice\", weight='bold'); axes[1].set_xlabel(\"Time (s)\"); axes[1].set_ylabel(\"Amplitude\")\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95]); plt.show(block=True)\n",
    "        if Confirm.ask(\"[bold]Save this figure?[/bold]\"):\n",
    "            save_path = Prompt.ask(\"[bold]Enter filename[/bold]\", default=\"voice_comparison.png\")\n",
    "            fig.savefig(save_path); console.print(f\"âœ… [bold green]Figure saved to {os.path.abspath(save_path)}[/bold green]\")\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]Could not generate visualization. Error: {e}[/bold red]\")\n",
    "\n",
    "# --- 5. Text-to-Speech Module ---\n",
    "def speak_text_with_cloning(text_to_speak, reference_audio_file, tts_model):\n",
    "    console.print(Panel(\"[bold]ðŸ—£ï¸ Advanced Text-to-Speech Engine[/bold]\", style=\"bright_cyan\", title=\"Cloning Voice\"))\n",
    "    \n",
    "    emotion_presets = {\n",
    "        \"1\": {\"name\": \"ðŸ˜Š Neutral\", \"params\": {\"temperature\": 0.75, \"speed\": 1.0}},\n",
    "        \"2\": {\"name\": \"ðŸ˜„ Happy\", \"params\": {\"temperature\": 0.8, \"speed\": 1.1}},\n",
    "        \"3\": {\"name\": \"ðŸ˜¢ Sad\", \"params\": {\"temperature\": 0.6, \"speed\": 0.9}},\n",
    "        \"4\": {\"name\": \"ðŸ˜  Angry\", \"params\": {\"temperature\": 0.7, \"speed\": 1.2, \"top_p\": 0.8}},\n",
    "        \"5\": {\"name\": \"ðŸ˜¨ Fearful\", \"params\": {\"temperature\": 0.9, \"speed\": 1.05}},\n",
    "        \"6\": {\"name\": \"ðŸ˜² Surprised\", \"params\": {\"temperature\": 0.75, \"speed\": 1.2}},\n",
    "        \"7\": {\"name\": \"â¤ï¸ Loving\", \"params\": {\"temperature\": 0.65, \"speed\": 0.95}},\n",
    "    }\n",
    "    \n",
    "    console.print(\"[bold]Choose an emotional tone for the synthesized voice:[/bold]\")\n",
    "    for key, val in emotion_presets.items():\n",
    "        console.print(f\"[{key}] {val['name']}\")\n",
    "    \n",
    "    choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=emotion_presets.keys(), default=\"1\")\n",
    "    chosen_emotion = emotion_presets[choice]\n",
    "    settings = chosen_emotion[\"params\"]\n",
    "\n",
    "    try:\n",
    "        console.print(f\"Synthesizing speech for: \\\"{text_to_speak}\\\"\")\n",
    "        console.print(f\"[italic]   (Applying [bold]{chosen_emotion['name']}[/bold] settings... this may take a moment)[/italic]\")\n",
    "        \n",
    "        tts_params = {\n",
    "            \"text\": text_to_speak,\n",
    "            \"speaker_wav\": reference_audio_file,\n",
    "            \"language\": \"en\",\n",
    "            \"file_path\": CLONED_FILENAME,\n",
    "            \"split_sentences\": True,\n",
    "            \"temperature\": settings.get(\"temperature\", 0.75),\n",
    "            \"speed\": settings.get(\"speed\", 1.0),\n",
    "            \"top_k\": settings.get(\"top_k\", 50),\n",
    "            \"top_p\": settings.get(\"top_p\", 0.85),\n",
    "        }\n",
    "        tts_model.tts_to_file(**tts_params)\n",
    "\n",
    "        if os.path.exists(CLONED_FILENAME):\n",
    "            console.print(\"ðŸ”Š [bold]Playing cloned voice...[/bold]\")\n",
    "            rate, data = wav.read(CLONED_FILENAME); sd.play(data, rate); sd.wait()\n",
    "            console.print(\"âœ… [bold green]Playback finished.[/bold green]\")\n",
    "            perform_quality_check(reference_audio_file, CLONED_FILENAME)\n",
    "            visualize_and_save_audio(reference_audio_file, CLONED_FILENAME)\n",
    "            if Confirm.ask(\"[bold]Save this synthesized audio?[/bold]\"):\n",
    "                save_path = Prompt.ask(\"[bold]Enter filename[/bold]\", default=f\"my_cloned_voice_{chosen_emotion['name'].split(' ')[1].lower()}.wav\")\n",
    "                shutil.copy(CLONED_FILENAME, save_path); console.print(f\"âœ… [bold green]Audio saved to {os.path.abspath(save_path)}[/bold green]\")\n",
    "        else: console.print(\"âŒ [bold red]Failed to create cloned voice output file.[/bold red]\")\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]An error occurred during voice cloning: {e}[/bold red]\")\n",
    "\n",
    "# --- 6. Main Application Logic ---\n",
    "def initialize_tts_model():\n",
    "    console.print(Panel(\"[bold]ðŸš€ Voice Cloning Model Setup[/bold]\", style=\"bright_cyan\"))\n",
    "    prompt_text = \"[bold]Choose a cloning model:[/bold]\\n[1] High-Quality (Coqui XTTSv2)\\n[2] Fast (Coqui VITS)\"\n",
    "    console.print(prompt_text); model_choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=[\"1\", \"2\"], default=\"1\")\n",
    "    model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\" if model_choice == '1' else \"tts_models/en/vctk/vits\"\n",
    "    try:\n",
    "        console.print(f\"\\nâ³ [italic]Loading model '{model_name}'...[/italic]\")\n",
    "        if hasattr(torch, 'serialization') and hasattr(torch.serialization, 'safe_globals'):\n",
    "            with torch.serialization.safe_globals([XttsConfig, XttsAudioConfig, BaseDatasetConfig, XttsArgs, BaseTTSConfig]):\n",
    "                tts_model = TTS(model_name, progress_bar=True, gpu=False)\n",
    "        else:\n",
    "            tts_model = TTS(model_name, progress_bar=True, gpu=False)\n",
    "        console.print(\"âœ… [bold green]Voice cloning model loaded successfully.[/bold green]\"); return tts_model\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]Could not load model. Error: {e}[/bold red]\"); return None\n",
    "\n",
    "def print_detailed_report(report):\n",
    "    METRIC_EXPLANATIONS = {\n",
    "        \"Mean Fundamental Frequency (Hz)\": \"The average perceived pitch of the voice. Higher values = higher pitch.\",\n",
    "        \"Mean F1 (Hz)\": \"A key resonant frequency related to vowel height (e.g., 'ee' vs 'ah').\",\n",
    "        \"Mean F2 (Hz)\": \"A resonant frequency related to the frontness/backness of a vowel.\",\n",
    "        \"Average Intensity (RMS)\": \"The root-mean-square energy, corresponding to perceived loudness.\",\n",
    "        \"Voice Segments Detected\": \"The number of times the script identified speech vs. silence.\",\n",
    "        \"Estimated SNR (dB)\": \"Signal-to-Noise Ratio. Higher is better, indicating clearer audio.\",\n",
    "        \"Polarity\": \"Sentiment score from -1.0 (very negative) to 1.0 (very positive).\",\n",
    "        \"Subjectivity\": \"How objective (0.0) vs. subjective (1.0) the language is.\",\n",
    "        \"Pitch Variation (Std Dev Hz)\": \"How much the pitch varies. Higher values indicate more expressive, melodic speech.\",\n",
    "        \"Jitter (Frequency Perturbation)\": \"The cycle-to-cycle variation in frequency. Can relate to vocal roughness or strain.\",\n",
    "        \"Shimmer (Amplitude Perturbation)\": \"The cycle-to-cycle variation in amplitude. Can relate to breathiness.\",\n",
    "        \"Estimated Gender\": \"A prediction based on typical male/female pitch ranges.\",\n",
    "        \"Speaking Rate (WPM)\": \"Words Per Minute, a measure of speech fluency and pace.\",\n",
    "        \"Number of Pauses\": \"The count of significant silent intervals during speech.\"\n",
    "    }\n",
    "    console.print(Panel(\"[bold]Full Analysis Report[/bold]\", style=\"green\", border_style=\"green\"))\n",
    "    for category, analyses in report.items():\n",
    "        if not analyses: continue\n",
    "        table = Table(title=f\"[bold bright_cyan]{category}[/bold bright_cyan]\", show_header=False, box=None, padding=(0, 2))\n",
    "        table.add_column(\"Metric\", style=\"bright_yellow\", width=35); table.add_column(\"Value\", width=30); table.add_column(\"Explanation\", style=\"dim\")\n",
    "        if \"Error\" in analyses: table.add_row(\"[bold red]Error[/bold red]\", analyses[\"Error\"])\n",
    "        else:\n",
    "            for sub_category, metrics in analyses.items():\n",
    "                table.add_row(f\"[bold underline]{sub_category}[/bold underline]\", \"\")\n",
    "                for metric, value in metrics.items():\n",
    "                    explanation = METRIC_EXPLANATIONS.get(metric, \"\")\n",
    "                    table.add_row(f\"  {metric}\", str(value), explanation)\n",
    "        console.print(table)\n",
    "\n",
    "def cleanup():\n",
    "    console.print(\"[bold green]Exiting the NLP Suite. God Speed![/bold green]\")\n",
    "    try:\n",
    "        sd.stop()\n",
    "        for f in [INPUT_FILENAME, CLEANED_FILENAME, CLONED_FILENAME]:\n",
    "            if os.path.exists(f): os.remove(f)\n",
    "        if Confirm.ask(\"[bold]Clear downloaded model cache to free up space?[/bold]\"):\n",
    "            tts_cache_path = os.path.join(os.path.expanduser(\"~\"), \".local\", \"share\", \"tts\")\n",
    "            if os.path.exists(tts_cache_path):\n",
    "                shutil.rmtree(tts_cache_path)\n",
    "                console.print(f\"âœ… [bold green]Model cache cleared from {tts_cache_path}[/bold green]\")\n",
    "            else: console.print(\"[bold yellow]Model cache directory not found.[/bold yellow]\")\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]An error occurred during cleanup: {e}[/bold red]\")\n",
    "    finally: sys.exit(0)\n",
    "\n",
    "def main_menu():\n",
    "    console.print(Panel(\"[bold]Welcome to the Voice NLP Suite Pro v4.0[/bold]\\n[bright_cyan]Dynamic Synthesis & Reporting[/bright_cyan]\", style=\"green\", title=\"Voice NLP Suite\"))\n",
    "    tts_model = initialize_tts_model()\n",
    "    is_audio_recorded = False; active_audio_file = None\n",
    "    while True:\n",
    "        console.print(Panel(\"[bold]Select an option[/bold]\", style=\"bright_cyan\", title=\"Main Menu\"))\n",
    "        preprocess_option = \"[2] Preprocess Audio (Noise Reduction)\" if is_audio_recorded else \"[dim][2] Preprocess Audio (Record first)[/dim]\"\n",
    "        analyze_option = \"[3] Analyze Voice\" if is_audio_recorded else \"[dim][3] Analyze Voice (Record first)[/dim]\"\n",
    "        tts_option = \"[4] Text-to-Speech (Cloned Voice)\" if is_audio_recorded else \"[dim][4] Text-to-Speech (Record first)[/dim]\"\n",
    "        prompt_text = f\"[bold]Choose an action:[/bold]\\n[1] Record Voice\\n{preprocess_option}\\n{analyze_option}\\n{tts_option}\\n[5] Exit\"\n",
    "        console.print(prompt_text)\n",
    "        choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=[\"1\", \"2\", \"3\", \"4\", \"5\"], default=\"1\")\n",
    "        if choice == '1':\n",
    "            try:\n",
    "                duration = int(Prompt.ask(\"[bold]Enter recording duration (5-15s recommended)[/bold]\", default=\"10\"))\n",
    "                record_audio(duration)\n",
    "                active_audio_file = INPUT_FILENAME\n",
    "                is_audio_recorded = True\n",
    "            except ValueError: console.print(\"âŒ [bold red]Invalid input. Please enter a number.[/bold red]\")\n",
    "        elif choice == '2':\n",
    "            if not is_audio_recorded: console.print(\"ðŸ”´ [bold red]Please record your voice first using option [1].[/bold red]\"); continue\n",
    "            active_audio_file = run_preprocessing_menu(INPUT_FILENAME, CLEANED_FILENAME)\n",
    "        elif choice == '3':\n",
    "            if not is_audio_recorded: console.print(\"ðŸ”´ [bold red]Please record your voice first using option [1].[/bold red]\"); continue\n",
    "            transcribed_text = transcribe_audio(active_audio_file)\n",
    "            if transcribed_text:\n",
    "                analyzer = VoiceAnalyzer(active_audio_file, transcribed_text)\n",
    "                full_report = {\n",
    "                    \"ðŸŽ™ï¸ Acoustic & Signal-Level Analysis\": analyzer.analyze_acoustic(),\n",
    "                    \"ðŸ§  Linguistic & Semantic Analysis\": analyzer.analyze_linguistic(),\n",
    "                    \"ðŸ˜ƒ Emotional & Behavioral Analysis\": analyzer.analyze_emotional(),\n",
    "                    \"ðŸ§¬ Biometric & Identity Analysis\": analyzer.analyze_biometric(),\n",
    "                    \"ðŸ› ï¸ Technical & Application-Specific Analysis\": analyzer.analyze_technical(),\n",
    "                }\n",
    "                print_detailed_report(full_report)\n",
    "        elif choice == '4':\n",
    "            if not is_audio_recorded: console.print(\"ðŸ”´ [bold red]Please record your voice first using option [1].[/bold red]\"); continue\n",
    "            if not tts_model: console.print(\"ðŸ”´ [bold red]TTS functionality is disabled.[/bold red]\"); continue\n",
    "            text_to_speak = Prompt.ask(\"[bold]Enter the text you want me to speak[/bold]\")\n",
    "            if text_to_speak: speak_text_with_cloning(text_to_speak, active_audio_file, tts_model)\n",
    "        elif choice == '5': cleanup()\n",
    "if __name__ == \"__main__\": main_menu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Voice NLP Suite (PRO Edition v5.0 - Expert Edition)\n",
    "Author: AI/ML Engineer (Gemini)\n",
    "Date: 2025-10-10\n",
    "Description: An expert-level suite for voice processing. This version exposes advanced\n",
    "             controls for the underlying AI models, including selectable speech recognition\n",
    "             model sizes and multilingual, prosody-controlled speech synthesis.\n",
    "\"\"\"\n",
    "# --- Suppress all warnings for a clean, user-friendly output ---\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Core Libraries ---\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import speech_recognition as sr\n",
    "import librosa\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import soundfile as sf # Moved for robust import\n",
    "\n",
    "# --- Optional Visualization & UI Libraries ---\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    VISUALIZATION_ENABLED = True\n",
    "except ImportError:\n",
    "    VISUALIZATION_ENABLED = False\n",
    "\n",
    "try:\n",
    "    from rich.console import Console\n",
    "    from rich.panel import Panel\n",
    "    from rich.prompt import Prompt, Confirm\n",
    "    from rich.table import Table\n",
    "    from rich.live import Live\n",
    "    RICH_UI_ENABLED = True\n",
    "except ImportError:\n",
    "    RICH_UI_ENABLED = False\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from TTS.api import TTS\n",
    "    from TTS.tts.configs.xtts_config import XttsConfig\n",
    "    from TTS.tts.models.xtts import XttsAudioConfig, XttsArgs\n",
    "    from TTS.tts.configs.shared_configs import BaseDatasetConfig, BaseTTSConfig\n",
    "    import parselmouth\n",
    "    from parselmouth.praat import call as praat_call\n",
    "    from langdetect import detect as detect_language\n",
    "    import noisereduce as nr\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ A required library is missing. Please ensure all dependencies are installed. Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Initialize UI ---\n",
    "if RICH_UI_ENABLED:\n",
    "    console = Console()\n",
    "else:\n",
    "    class FallbackConsole:\n",
    "        def print(self, text): print(text)\n",
    "    console = FallbackConsole()\n",
    "\n",
    "# --- Configuration ---\n",
    "SAMPLE_RATE = 22050\n",
    "INPUT_FILENAME = \"user_voice_input.wav\"\n",
    "CLEANED_FILENAME = \"cleaned_user_voice.wav\"\n",
    "CLONED_FILENAME = \"cloned_voice_output.wav\"\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    console.print(\"[bold bright_yellow]spaCy model 'en_core_web_sm' not found. Downloading...[/bold bright_yellow]\")\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "os.environ['COQUI_TOS_AGREED'] = '1'\n",
    "\n",
    "# --- 1. Voice Capture & Preprocessing ---\n",
    "def record_audio(duration=10):\n",
    "    console.print(f\"\\nðŸŽ™ï¸ [bold bright_cyan]Starting recording for {duration} seconds...[/bold bright_cyan]\")\n",
    "    recording = sd.rec(int(duration * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='int16')\n",
    "    \n",
    "    if RICH_UI_ENABLED:\n",
    "        with Live(console=console, screen=False, auto_refresh=False) as live:\n",
    "            for i in range(duration, 0, -1):\n",
    "                live.update(f\"   [bold yellow]Recording... {i}s remaining[/bold yellow]\", refresh=True)\n",
    "                time.sleep(1)\n",
    "    else:\n",
    "        for i in range(duration, 0, -1):\n",
    "            print(f\"   Recording... {i}s remaining\", end='\\r')\n",
    "            time.sleep(1)\n",
    "        print()\n",
    "\n",
    "    sd.wait()\n",
    "    wav.write(INPUT_FILENAME, SAMPLE_RATE, recording)\n",
    "    console.print(f\"âœ… [bold green]Audio successfully saved to {INPUT_FILENAME}[/bold green]\")\n",
    "    return INPUT_FILENAME\n",
    "\n",
    "def run_preprocessing_menu(input_file, output_file):\n",
    "    console.print(Panel(\"[bold]ðŸ§¹ Optional Audio Preprocessing[/bold]\", style=\"bright_cyan\", title=\"Noise Reduction\"))\n",
    "    if not Confirm.ask(\"[bold]Do you want to apply noise reduction to the recorded audio?[/bold]\"):\n",
    "        console.print(\"[bold yellow]Skipping noise reduction. Using original audio.[/bold yellow]\")\n",
    "        return input_file\n",
    "\n",
    "    prompt_text = (\n",
    "        \"[bold]Choose a noise reduction method:[/bold]\\n\"\n",
    "        \"[1] Soft     - [cyan]Basic filter for minor hiss or hum.[/cyan]\\n\"\n",
    "        \"[2] Moderate - [yellow]Profile-based reduction for steady background noise.[/yellow]\\n\"\n",
    "        \"[3] Robust   - [red]Aggressive vocal isolation for complex environments.[/red]\"\n",
    "    )\n",
    "    console.print(prompt_text)\n",
    "    choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=[\"1\", \"2\", \"3\"], default=\"2\")\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=SAMPLE_RATE)\n",
    "        \n",
    "        if choice == '1': # Soft\n",
    "            console.print(\"[italic]Applying soft noise reduction...[/italic]\")\n",
    "            reduced_noise = nr.reduce_noise(y=y, sr=sr, prop_decrease=0.8)\n",
    "        \n",
    "        elif choice == '2': # Moderate\n",
    "            console.print(\"[italic]Applying moderate (profile-based) noise reduction...[/italic]\")\n",
    "            non_silent = librosa.effects.split(y, top_db=30)\n",
    "            noise_clip = y[0:non_silent[0][0]] if len(non_silent) > 0 and non_silent[0][0] > 0 else y[0:int(sr*0.5)]\n",
    "            reduced_noise = nr.reduce_noise(y=y, y_noise=noise_clip, sr=sr, prop_decrease=0.95)\n",
    "        \n",
    "        elif choice == '3': # Robust\n",
    "            console.print(\"[italic]Applying robust vocal isolation...[/italic]\")\n",
    "            reduced_noise, _ = librosa.effects.hpss(y)\n",
    "\n",
    "        sf.write(output_file, reduced_noise, sr)\n",
    "        console.print(f\"âœ… [bold green]Noise reduction complete. Using cleaned audio.[/bold green]\")\n",
    "        return output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        console.print(f\"âŒ [bold red]Could not perform noise reduction: {e}. Using original audio.[/bold red]\")\n",
    "        return input_file\n",
    "\n",
    "\n",
    "# --- 2. Speech Recognition Engine ---\n",
    "def transcribe_audio(audio_file, model_size=\"base.en\"):\n",
    "    console.print(f\"\\nðŸ§  [bold bright_cyan]Transcribing with Whisper ({model_size} model)...[/bold bright_cyan]\")\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.AudioFile(audio_file) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "        text = recognizer.recognize_whisper(audio_data, model=model_size, language=\"english\")\n",
    "        console.print(f\"ðŸ“ [bold green]Transcription:[/bold green] \\\"{text}\\\"\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        console.print(f\"âŒ [bold red]An error occurred during transcription: {e}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "# --- 3. Core Analysis Engine (Fully Implemented) ---\n",
    "class VoiceAnalyzer:\n",
    "    def __init__(self, audio_file, transcribed_text):\n",
    "        if not os.path.exists(audio_file):\n",
    "            raise FileNotFoundError(f\"Audio file not found at {audio_file}\")\n",
    "        self.audio_file = audio_file\n",
    "        self.text = transcribed_text if transcribed_text else \"\"\n",
    "        self.y, self.sr = librosa.load(self.audio_file, sr=SAMPLE_RATE)\n",
    "        self.duration_seconds = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        self.sound = parselmouth.Sound(self.audio_file)\n",
    "\n",
    "    def analyze_acoustic(self):\n",
    "        try:\n",
    "            pitch = praat_call(self.sound, \"To Pitch\", 0.0, 75, 600)\n",
    "            mean_pitch = praat_call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "            formant = praat_call(self.sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 50)\n",
    "            f1_mean = praat_call(formant, \"Get mean\", 1, 0, 0, \"Hertz\")\n",
    "            f2_mean = praat_call(formant, \"Get mean\", 2, 0, 0, \"Hertz\")\n",
    "            rms = librosa.feature.rms(y=self.y)[0]\n",
    "            non_silent_intervals = librosa.effects.split(self.y, top_db=30)\n",
    "            snr = 20 * np.log10(np.mean(rms[non_silent_intervals[0][0]:non_silent_intervals[-1][1]]) / np.mean(rms[:non_silent_intervals[0][0]])) if len(non_silent_intervals) > 1 else 'N/A'\n",
    "\n",
    "            return {\n",
    "                \"Pitch & Tone\": {\"Mean Fundamental Frequency (Hz)\": f\"{mean_pitch:.2f}\"},\n",
    "                \"Formant (Vowel) Analysis\": {\"Mean F1 (Hz)\": f\"{f1_mean:.2f}\", \"Mean F2 (Hz)\": f\"{f2_mean:.2f}\"},\n",
    "                \"Energy & Loudness\": {\"Average Intensity (RMS)\": f\"{np.mean(rms):.4f}\"},\n",
    "                \"Audio Quality\": {\"Voice Segments Detected\": f\"{len(non_silent_intervals)}\", \"Estimated SNR (dB)\": f\"{snr}\" if isinstance(snr, float) else snr},\n",
    "                \"Feature Extraction\": {\"Method\": \"Log-Mel Spectrograms (internal to Whisper model)\"}\n",
    "            }\n",
    "        except Exception as e: return {\"Error\": f\"Analysis failed. {e}\"}\n",
    "\n",
    "    def analyze_linguistic(self):\n",
    "        if not self.text: return {\"Error\": \"No text to analyze.\"}\n",
    "        doc = nlp(self.text)\n",
    "        blob = TextBlob(self.text)\n",
    "        intent = \"Informational\"\n",
    "        if any(token.lemma_ in [\"can\", \"what\", \"who\", \"where\", \"when\", \"why\", \"how\"] for token in doc) and \"?\" in self.text: intent = \"Question\"\n",
    "        elif doc and doc[0].pos_ == \"VERB\": intent = \"Command/Imperative\"\n",
    "\n",
    "        return {\n",
    "            \"Transcription\": {\"Full Text\": self.text},\n",
    "            \"Language Model\": {\"Acoustic Model\": \"Whisper (Transformer-based)\", \"Decoding\": \"Beam Search (Greedy)\"},\n",
    "            \"Semantic Content\": {\"Named Entities (NER)\": [(ent.text, ent.label_) for ent in doc.ents] or \"None detected\", \"Keywords\": [chunk.text for chunk in doc.noun_chunks] or \"None detected\"},\n",
    "            \"Sentiment & Intent\": {\"Polarity\": f\"{blob.sentiment.polarity:.2f}\", \"Subjectivity\": f\"{blob.sentiment.subjectivity:.2f}\", \"Inferred Intent\": intent}\n",
    "        }\n",
    "\n",
    "    def analyze_emotional(self):\n",
    "        try:\n",
    "            jitter = \"N/A\"; shimmer = \"N/A\"; std_dev_pitch_str = \"N/A\"\n",
    "            try:\n",
    "                pitch = praat_call(self.sound, \"To Pitch\", 0.0, 75, 600)\n",
    "                std_dev_pitch = praat_call(pitch, \"Get standard deviation\", 0, 0, \"Hertz\")\n",
    "                std_dev_pitch_str = f\"{std_dev_pitch:.2f}\"\n",
    "            except Exception: pass\n",
    "            try:\n",
    "                point_process = praat_call(self.sound, \"To PointProcess (periodic, cc)\", 75, 600)\n",
    "                if praat_call(point_process, \"Get number of points\") > 1:\n",
    "                    jitter = f\"{praat_call(point_process, 'Get jitter (local)', 0, 0, 0.0001, 0.02, 1.3) * 100:.4f}%\"\n",
    "                    shimmer = f\"{praat_call(point_process, 'Get shimmer (local)', 0, 0, 0.0001, 0.02, 1.3, 1.6) * 100:.4f}%\"\n",
    "            except Exception: pass\n",
    "            return {\n",
    "                \"Prosody & Expressiveness\": {\"Pitch Variation (Std Dev Hz)\": std_dev_pitch_str},\n",
    "                \"Vocal Strain/Stability\": {\"Jitter\": jitter, \"Shimmer\": shimmer}\n",
    "            }\n",
    "        except Exception as e: return {\"Error\": f\"A fundamental analysis error occurred. Details: {e}\"}\n",
    "\n",
    "    def analyze_biometric(self):\n",
    "        try:\n",
    "            pitch = praat_call(self.sound, \"To Pitch\", 0.0, 75, 600)\n",
    "            mean_pitch = praat_call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "            gender = \"Undetermined\"\n",
    "            if 85 < mean_pitch < 180: gender = \"Likely Male\"\n",
    "            elif 165 < mean_pitch < 255: gender = \"Likely Female\"\n",
    "            return {\n",
    "                \"Identity Estimation\": {\"Estimated Gender\": f\"{gender} (based on {mean_pitch:.2f} Hz avg pitch)\"},\n",
    "                \"Speaker Adaptation\": {\"Method\": \"Zero-Shot Cloning via Coqui XTTS\"}\n",
    "            }\n",
    "        except Exception as e: return {\"Error\": f\"Analysis failed. {e}\"}\n",
    "\n",
    "    def analyze_technical(self):\n",
    "        if not self.text: return {\"Error\": \"No text to analyze.\"}\n",
    "        try: language = detect_language(self.text).upper()\n",
    "        except: language = \"Detection failed\"\n",
    "        non_silent_intervals = librosa.effects.split(self.y, top_db=30)\n",
    "        speaking_rate = (len(self.text.split()) / self.duration_seconds) * 60 if self.duration_seconds > 0 else 0\n",
    "        return {\n",
    "            \"Speech Fluency\": {\"Speaking Rate (WPM)\": f\"{speaking_rate:.2f}\", \"Number of Pauses\": max(0, len(non_silent_intervals) - 1)},\n",
    "            \"Content Spotting\": {\"Detected Language\": language}\n",
    "        }\n",
    "\n",
    "# --- 4. Quality & Visualization Modules ---\n",
    "def perform_quality_check(original_file, cloned_file):\n",
    "    console.print(\"\\nðŸ” [bold bright_cyan]Performing automated quality check...[/bold bright_cyan]\")\n",
    "    try:\n",
    "        y_orig, _ = librosa.load(original_file, sr=SAMPLE_RATE)\n",
    "        y_cloned, _ = librosa.load(cloned_file, sr=SAMPLE_RATE)\n",
    "        rms_orig = librosa.feature.rms(y=y_orig)[0]\n",
    "        rms_cloned = librosa.feature.rms(y=y_cloned)[0]\n",
    "        ratio = np.std(rms_cloned) / np.std(rms_orig) if np.std(rms_orig) > 0 else 0\n",
    "        if ratio < 0.6: console.print(f\"âš ï¸ [bold bright_yellow]Quality Warning:[/bold bright_yellow] Synthesized voice has less dynamic range ({ratio:.2f} ratio).\")\n",
    "        else: console.print(f\"âœ… [bold green]Quality Check Passed:[/bold green] Similar dynamic range to original ({ratio:.2f} ratio).\")\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]Could not perform quality check. Error: {e}[/bold red]\")\n",
    "\n",
    "def visualize_and_save_audio(original_file, cloned_file):\n",
    "    if not VISUALIZATION_ENABLED: return\n",
    "    console.print(\"\\nðŸ“Š [bold bright_cyan]Generating voice waveform comparison...[/bold bright_cyan]\")\n",
    "    try:\n",
    "        y_orig, sr_orig = librosa.load(original_file, sr=SAMPLE_RATE)\n",
    "        y_cloned, sr_cloned = librosa.load(cloned_file, sr=SAMPLE_RATE)\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True, sharey=True)\n",
    "        fig.suptitle('Voice Waveform Comparison', fontsize=16, weight='bold')\n",
    "        librosa.display.waveshow(y_orig, sr=sr_orig, ax=axes[0], color='royalblue'); axes[0].set_title(\"Original Recorded Voice\", weight='bold'); axes[0].set_ylabel(\"Amplitude\")\n",
    "        librosa.display.waveshow(y_cloned, sr=sr_cloned, ax=axes[1], color='darkorange'); axes[1].set_title(\"Synthesized (Cloned) Voice\", weight='bold'); axes[1].set_xlabel(\"Time (s)\"); axes[1].set_ylabel(\"Amplitude\")\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95]); plt.show(block=True)\n",
    "        if Confirm.ask(\"[bold]Save this figure?[/bold]\"):\n",
    "            save_path = Prompt.ask(\"[bold]Enter filename[/bold]\", default=\"voice_comparison.png\")\n",
    "            fig.savefig(save_path); console.print(f\"âœ… [bold green]Figure saved to {os.path.abspath(save_path)}[/bold green]\")\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]Could not generate visualization. Error: {e}[/bold red]\")\n",
    "\n",
    "# --- 5. Text-to-Speech Module ---\n",
    "def speak_text_with_cloning(text_to_speak, reference_audio_file, tts_model):\n",
    "    console.print(Panel(\"[bold]ðŸ—£ï¸ Advanced Text-to-Speech Engine[/bold]\", style=\"bright_cyan\", title=\"Cloning Voice\"))\n",
    "    \n",
    "    prosody_presets = {\n",
    "        \"1\": {\"name\": \"ðŸ˜Š Neutral\", \"params\": {\"temperature\": 0.75, \"speed\": 1.0}},\n",
    "        \"2\": {\"name\": \"ðŸ˜„ Happy\", \"params\": {\"temperature\": 0.8, \"speed\": 1.1, \"top_p\": 0.8}},\n",
    "        \"3\": {\"name\": \"ðŸ˜¢ Sad\", \"params\": {\"temperature\": 0.6, \"speed\": 0.9, \"top_p\": 0.9}},\n",
    "        \"4\": {\"name\": \"ðŸ˜  Angry\", \"params\": {\"temperature\": 0.7, \"speed\": 1.2, \"repetition_penalty\": 1.5}},\n",
    "        \"5\": {\"name\": \"â¤ï¸ Loving\", \"params\": {\"temperature\": 0.65, \"speed\": 0.95, \"top_p\": 0.9}},\n",
    "    }\n",
    "    \n",
    "    languages = {\"1\": \"en\", \"2\": \"es\", \"3\": \"fr\", \"4\": \"de\", \"5\": \"it\", \"6\": \"pt\", \"7\": \"pl\", \"8\": \"tr\", \"9\": \"ru\", \"10\": \"nl\", \"11\": \"cs\", \"12\": \"ar\", \"13\": \"zh-cn\"}\n",
    "    \n",
    "    console.print(\"[bold]Choose a language for synthesis:[/bold]\")\n",
    "    console.print(\"[1] English [2] Spanish [3] French [4] German [5] Italian [6] Portuguese [7] Polish [8] Turkish [9] Russian [10] Dutch [11] Czech [12] Arabic [13] Chinese\")\n",
    "    lang_choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=languages.keys(), default=\"1\")\n",
    "    chosen_lang = languages[lang_choice]\n",
    "\n",
    "    console.print(\"\\n[bold]Choose a tone & prosody style:[/bold]\")\n",
    "    for key, val in prosody_presets.items(): console.print(f\"[{key}] {val['name']}\")\n",
    "    \n",
    "    choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=prosody_presets.keys(), default=\"1\")\n",
    "    chosen_prosody = prosody_presets[choice]\n",
    "    settings = chosen_prosody[\"params\"]\n",
    "\n",
    "    try:\n",
    "        console.print(f\"Synthesizing speech for: \\\"{text_to_speak}\\\"\")\n",
    "        console.print(f\"[italic]   (Applying [bold]{chosen_prosody['name']}[/bold] prosody in [bold]{chosen_lang.upper()}[/bold]... this may take a moment)[/italic]\")\n",
    "        \n",
    "        tts_params = { \"text\": text_to_speak, \"speaker_wav\": reference_audio_file, \"language\": chosen_lang, \"file_path\": CLONED_FILENAME, **settings }\n",
    "        tts_model.tts_to_file(**tts_params)\n",
    "\n",
    "        if os.path.exists(CLONED_FILENAME):\n",
    "            console.print(\"ðŸ”Š [bold]Playing cloned voice...[/bold]\")\n",
    "            rate, data = wav.read(CLONED_FILENAME); sd.play(data, rate); sd.wait()\n",
    "            console.print(\"âœ… [bold green]Playback finished.[/bold green]\")\n",
    "            perform_quality_check(reference_audio_file, CLONED_FILENAME)\n",
    "            visualize_and_save_audio(reference_audio_file, CLONED_FILENAME)\n",
    "            if Confirm.ask(\"[bold]Save this synthesized audio?[/bold]\"):\n",
    "                save_path = Prompt.ask(\"[bold]Enter filename[/bold]\", default=f\"my_cloned_voice_{chosen_prosody['name'].split(' ')[1].lower()}.wav\")\n",
    "                shutil.copy(CLONED_FILENAME, save_path); console.print(f\"âœ… [bold green]Audio saved to {os.path.abspath(save_path)}[/bold green]\")\n",
    "        else: console.print(\"âŒ [bold red]Failed to create cloned voice output file.[/bold red]\")\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]An error occurred during voice cloning: {e}[/bold red]\")\n",
    "\n",
    "# --- 6. Main Application Logic ---\n",
    "def initialize_tts_model():\n",
    "    console.print(Panel(\"[bold]ðŸš€ Voice Cloning Model Setup[/bold]\", style=\"bright_cyan\"))\n",
    "    model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "    try:\n",
    "        console.print(f\"\\nâ³ [italic]Loading model '{model_name}'...[/italic]\")\n",
    "        if hasattr(torch, 'serialization') and hasattr(torch.serialization, 'safe_globals'):\n",
    "            with torch.serialization.safe_globals([XttsConfig, XttsAudioConfig, BaseDatasetConfig, XttsArgs, BaseTTSConfig]):\n",
    "                tts_model = TTS(model_name, progress_bar=True, gpu=False)\n",
    "        else:\n",
    "            tts_model = TTS(model_name, progress_bar=True, gpu=False)\n",
    "        console.print(\"âœ… [bold green]Voice cloning model loaded successfully.[/bold green]\"); return tts_model\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]Could not load model. Error: {e}[/bold red]\"); return None\n",
    "\n",
    "def print_detailed_report(report):\n",
    "    METRIC_EXPLANATIONS = {\n",
    "        \"Mean Fundamental Frequency (Hz)\": \"The average perceived pitch of the voice.\",\n",
    "        \"Average Intensity (RMS)\": \"Corresponds to perceived loudness.\",\n",
    "        \"Estimated SNR (dB)\": \"Signal-to-Noise Ratio. Higher is better.\",\n",
    "        \"Polarity\": \"Sentiment score from -1.0 (negative) to 1.0 (positive).\",\n",
    "        \"Pitch Variation (Std Dev Hz)\": \"Higher values indicate more expressive, melodic speech.\",\n",
    "        \"Jitter\": \"Cycle-to-cycle frequency variation. Can relate to vocal roughness.\",\n",
    "        \"Shimmer\": \"Cycle-to-cycle amplitude variation. Can relate to breathiness.\",\n",
    "        \"Speaking Rate (WPM)\": \"Words Per Minute, a measure of speech pace.\",\n",
    "        \"Acoustic Model\": \"The deep learning model used for audio-to-text conversion.\",\n",
    "        \"Method\": \"Indicates the technique used for the task.\",\n",
    "    }\n",
    "    console.print(Panel(\"[bold]Full Analysis Report[/bold]\", style=\"green\", border_style=\"green\"))\n",
    "    for category, analyses in report.items():\n",
    "        if not analyses: continue\n",
    "        table = Table(title=f\"[bold bright_cyan]{category}[/bold bright_cyan]\", show_header=False, box=None, padding=(0, 2))\n",
    "        table.add_column(\"Metric\", style=\"bright_yellow\", width=35); table.add_column(\"Value\", width=30); table.add_column(\"Explanation\", style=\"dim\")\n",
    "        if \"Error\" in analyses: table.add_row(\"[bold red]Error[/bold red]\", analyses[\"Error\"])\n",
    "        else:\n",
    "            for sub_category, metrics in analyses.items():\n",
    "                table.add_row(f\"[bold underline]{sub_category}[/bold underline]\", \"\")\n",
    "                for metric, value in metrics.items():\n",
    "                    explanation = METRIC_EXPLANATIONS.get(metric, \"\")\n",
    "                    table.add_row(f\"  {metric}\", str(value), explanation)\n",
    "        console.print(table)\n",
    "\n",
    "def cleanup():\n",
    "    console.print(\"[bold green]Exiting the NLP Suite. God Speed![/bold green]\")\n",
    "    try:\n",
    "        sd.stop()\n",
    "        for f in [INPUT_FILENAME, CLEANED_FILENAME, CLONED_FILENAME]:\n",
    "            if os.path.exists(f): os.remove(f)\n",
    "        if Confirm.ask(\"[bold]Clear downloaded model cache to free up space?[/bold]\"):\n",
    "            tts_cache_path = os.path.join(os.path.expanduser(\"~\"), \".local\", \"share\", \"tts\")\n",
    "            if os.path.exists(tts_cache_path): shutil.rmtree(tts_cache_path)\n",
    "    except Exception: pass\n",
    "    finally: sys.exit(0)\n",
    "\n",
    "def main_menu():\n",
    "    console.print(Panel(\"[bold]Welcome to the Voice NLP Suite Pro v5.0[/bold]\\n[bright_cyan]Expert Edition[/bright_cyan]\", style=\"green\", title=\"Voice NLP Suite\"))\n",
    "    tts_model = initialize_tts_model()\n",
    "    is_audio_recorded = False; active_audio_file = None\n",
    "    while True:\n",
    "        console.print(Panel(\"[bold]Select an option[/bold]\", style=\"bright_cyan\", title=\"Main Menu\"))\n",
    "        preprocess_option = \"[2] Preprocess Audio\" if is_audio_recorded else \"[dim][2] Preprocess Audio (Record first)[/dim]\"\n",
    "        analyze_option = \"[3] Analyze Voice\" if is_audio_recorded else \"[dim][3] Analyze Voice (Record first)[/dim]\"\n",
    "        tts_option = \"[4] Text-to-Speech\" if is_audio_recorded else \"[dim][4] Text-to-Speech (Record first)[/dim]\"\n",
    "        prompt_text = f\"[bold]Choose an action:[/bold]\\n[1] Record Voice\\n{preprocess_option}\\n{analyze_option}\\n{tts_option}\\n[5] Exit\"\n",
    "        console.print(prompt_text)\n",
    "        choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=[\"1\", \"2\", \"3\", \"4\", \"5\"], default=\"1\")\n",
    "        if choice == '1':\n",
    "            try:\n",
    "                duration = int(Prompt.ask(\"[bold]Enter recording duration (5-15s recommended)[/bold]\", default=\"10\"))\n",
    "                record_audio(duration); active_audio_file = INPUT_FILENAME; is_audio_recorded = True\n",
    "            except ValueError: console.print(\"âŒ [bold red]Invalid input.[/bold red]\")\n",
    "        elif choice == '2':\n",
    "            if not is_audio_recorded: console.print(\"ðŸ”´ [bold red]Please record your voice first.[/bold red]\"); continue\n",
    "            active_audio_file = run_preprocessing_menu(INPUT_FILENAME, CLEANED_FILENAME)\n",
    "        elif choice == '3':\n",
    "            if not is_audio_recorded: console.print(\"ðŸ”´ [bold red]Please record your voice first.[/bold red]\"); continue\n",
    "            console.print(\"[bold]Choose Whisper model size (larger is more accurate but slower):[/bold]\")\n",
    "            model_size = Prompt.ask(\"[1] Base [2] Medium [3] Large\", choices=[\"1\", \"2\", \"3\"], default=\"1\")\n",
    "            model_map = {\"1\": \"base.en\", \"2\": \"medium.en\", \"3\": \"large.en\"}\n",
    "            transcribed_text = transcribe_audio(active_audio_file, model_map[model_size])\n",
    "            if transcribed_text:\n",
    "                analyzer = VoiceAnalyzer(active_audio_file, transcribed_text)\n",
    "                full_report = {\n",
    "                    \"ðŸŽ™ï¸ Acoustic & Signal-Level Analysis\": analyzer.analyze_acoustic(),\n",
    "                    \"ðŸ§  Linguistic & Semantic Analysis\": analyzer.analyze_linguistic(),\n",
    "                    \"ðŸ˜ƒ Emotional & Behavioral Analysis\": analyzer.analyze_emotional(),\n",
    "                    \"ðŸ§¬ Biometric & Identity Analysis\": analyzer.analyze_biometric(),\n",
    "                    \"ðŸ› ï¸ Technical & Application-Specific Analysis\": analyzer.analyze_technical(),\n",
    "                }\n",
    "                print_detailed_report(full_report)\n",
    "        elif choice == '4':\n",
    "            if not is_audio_recorded: console.print(\"ðŸ”´ [bold red]Please record your voice first.[/bold red]\"); continue\n",
    "            if not tts_model: console.print(\"ðŸ”´ [bold red]TTS is disabled.[/bold red]\"); continue\n",
    "            text_to_speak = Prompt.ask(\"[bold]Enter the text to synthesize[/bold]\")\n",
    "            if text_to_speak: speak_text_with_cloning(text_to_speak, active_audio_file, tts_model)\n",
    "        elif choice == '5': cleanup()\n",
    "if __name__ == \"__main__\": main_menu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c00ec2",
   "metadata": {},
   "source": [
    "HINDI LANGUAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21455891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Voice NLP Suite â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚ </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Welcome to the Voice NLP Suite Pro v6.0</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                         â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚ </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">Advanced Workflow Edition</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                                       â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m Voice NLP Suite \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mWelcome to the Voice NLP Suite Pro v6.0\u001b[0m\u001b[32m                                                                        \u001b[0m\u001b[32m \u001b[0m\u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m\u001b[32m \u001b[0m\u001b[96mAdvanced Workflow Edition\u001b[0m\u001b[32m                                                                                      \u001b[0m\u001b[32m \u001b[0m\u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â”‚ </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">ðŸš€ Voice Cloning Model Setup</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">                                                                                    â”‚</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[96mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
       "\u001b[96mâ”‚\u001b[0m\u001b[96m \u001b[0m\u001b[1;96mðŸš€ Voice Cloning Model Setup\u001b[0m\u001b[96m                                                                                   \u001b[0m\u001b[96m \u001b[0m\u001b[96mâ”‚\u001b[0m\n",
       "\u001b[96mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "â³ <span style=\"font-style: italic\">Loading model </span><span style=\"color: #008000; text-decoration-color: #008000; font-style: italic\">'tts_models/multilingual/multi-dataset/xtts_v2'</span><span style=\"font-style: italic\"> </span><span style=\"font-weight: bold; font-style: italic\">(</span><span style=\"font-style: italic\">this happens once</span><span style=\"font-weight: bold; font-style: italic\">)</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "â³ \u001b[3mLoading model \u001b[0m\u001b[3;32m'tts_models/multilingual/multi-dataset/xtts_v2'\u001b[0m\u001b[3m \u001b[0m\u001b[1;3m(\u001b[0m\u001b[3mthis happens once\u001b[0m\u001b[1;3m)\u001b[0m\u001b[3;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ… <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Voice cloning model ready.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ… \u001b[1;32mVoice cloning model ready.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Main Menu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â”‚ </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">Select an option</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">                                                                                                â”‚</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[96mâ•­â”€\u001b[0m\u001b[96mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[96m Main Menu \u001b[0m\u001b[96mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[96mâ”€â•®\u001b[0m\n",
       "\u001b[96mâ”‚\u001b[0m\u001b[96m \u001b[0m\u001b[1;96mSelect an option\u001b[0m\u001b[96m                                                                                               \u001b[0m\u001b[96m \u001b[0m\u001b[96mâ”‚\u001b[0m\n",
       "\u001b[96mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Choose an action:</span>\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Input Voice\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">2</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Analyze Voice </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Input first</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">[</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">3</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">]</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Text-to-Speech </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Input first</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span> Exit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mChoose an action:\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Input Voice\n",
       "\u001b[1;2m[\u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m Analyze Voice \u001b[0m\u001b[1;2m(\u001b[0m\u001b[2mInput first\u001b[0m\u001b[1;2m)\u001b[0m\n",
       "\u001b[1;2m[\u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[1;2m]\u001b[0m\u001b[2m Text-to-Speech \u001b[0m\u001b[1;2m(\u001b[0m\u001b[2mInput first\u001b[0m\u001b[1;2m)\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m Exit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Enter your choice</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[1/2/3/4]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(1)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEnter your choice\u001b[0m \u001b[1;35m[1/2/3/4]\u001b[0m \u001b[1;36m(1)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">How would you like to provide audio?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mHow would you like to provide audio?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">[1] Record Voice\n",
       "[2] Select a File <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[1/2]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(1)</span>: </pre>\n"
      ],
      "text/plain": [
       "[1] Record Voice\n",
       "[2] Select a File \u001b[1;35m[1/2]\u001b[0m \u001b[1;36m(1)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Enter recording duration (5-15s recommended)</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(10)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEnter recording duration (5-15s recommended)\u001b[0m \u001b[1;36m(10)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸŽ™ï¸ <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">Starting recording for </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">14</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\"> seconds...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸŽ™ï¸ \u001b[1;96mStarting recording for \u001b[0m\u001b[1;96m14\u001b[0m\u001b[1;96m seconds\u001b[0m\u001b[1;96m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ… <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Audio successfully saved as user_voice_input.wav</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ… \u001b[1;32mAudio successfully saved as user_voice_input.wav\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Do you want to apply noise reduction?</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[y/n]</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDo you want to apply noise reduction?\u001b[0m \u001b[1;35m[y/n]\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Main Menu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â”‚ </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">Select an option</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">                                                                                                â”‚</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[96mâ•­â”€\u001b[0m\u001b[96mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[96m Main Menu \u001b[0m\u001b[96mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[96mâ”€â•®\u001b[0m\n",
       "\u001b[96mâ”‚\u001b[0m\u001b[96m \u001b[0m\u001b[1;96mSelect an option\u001b[0m\u001b[96m                                                                                               \u001b[0m\u001b[96m \u001b[0m\u001b[96mâ”‚\u001b[0m\n",
       "\u001b[96mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Choose an action:</span>\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Input Voice\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> Analyze Voice\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span> Text-to-Speech\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span> Exit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mChoose an action:\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Input Voice\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m Analyze Voice\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m Text-to-Speech\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m Exit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Enter your choice</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[1/2/3/4]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(1)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEnter your choice\u001b[0m \u001b[1;35m[1/2/3/4]\u001b[0m \u001b[1;36m(1)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Enter the text to synthesize</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEnter the text to synthesize\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Cloning Voice â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â”‚ </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">ðŸ—£ï¸ Advanced Text-to-Speech Engine</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">                                                                                â”‚</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[96mâ•­â”€\u001b[0m\u001b[96mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[96m Cloning Voice \u001b[0m\u001b[96mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[96mâ”€â•®\u001b[0m\n",
       "\u001b[96mâ”‚\u001b[0m\u001b[96m \u001b[0m\u001b[1;96mðŸ—£ï¸ Advanced Text-to-Speech Engine\u001b[0m\u001b[96m                                                                               \u001b[0m\u001b[96m \u001b[0m\u001b[96mâ”‚\u001b[0m\n",
       "\u001b[96mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Choose a language for synthesis:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mChoose a language for synthesis:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Hindi\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Hindi\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> English\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m English\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span> French\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m French\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span> Russian\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m Russian\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">]</span> Chinese\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m Chinese\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Enter your choice</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[1/2/3/4/5]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(2)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEnter your choice\u001b[0m \u001b[1;35m[1/2/3/4/5]\u001b[0m \u001b[1;36m(2)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-style: italic\">Translating text to English</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[3mTranslating text to English\u001b[0m\u001b[3;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ… <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Translated Text:</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"Pitch and tone detection: Identifies fundamental frequency and intonation patterns.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ… \u001b[1;32mTranslated Text:\u001b[0m \u001b[32m\"Pitch and tone detection: Identifies fundamental frequency and intonation patterns.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-style: italic\">Synthesizing </span><span style=\"color: #008000; text-decoration-color: #008000; font-style: italic\">'English'</span><span style=\"font-style: italic\"> speech</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[3mSynthesizing \u001b[0m\u001b[3;32m'English'\u001b[0m\u001b[3m speech\u001b[0m\u001b[3;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Pitch and tone detection: Identifies fundamental frequency and intonation patterns.']\n",
      " > Processing time: 43.33799767494202\n",
      " > Real-time factor: 5.433019016263028\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ”Š <span style=\"font-weight: bold\">Playing cloned voice</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ”Š \u001b[1mPlaying cloned voice\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ… <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Playback finished.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ… \u001b[1;32mPlayback finished.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸ“Š <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">Generating voice waveform comparison...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸ“Š \u001b[1;96mGenerating voice waveform comparison\u001b[0m\u001b[1;96m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â”‚ </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">ðŸ’¾ Save Artifacts</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">                                                                                               â”‚</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[96mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
       "\u001b[96mâ”‚\u001b[0m\u001b[96m \u001b[0m\u001b[1;96mðŸ’¾ Save Artifacts\u001b[0m\u001b[96m                                                                                              \u001b[0m\u001b[96m \u001b[0m\u001b[96mâ”‚\u001b[0m\n",
       "\u001b[96mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Select which files you want to save (e.g., </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'1'</span><span style=\"font-weight: bold\"> or </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'1,3'</span><span style=\"font-weight: bold\">):</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSelect which files you want to save \u001b[0m\u001b[1m(\u001b[0m\u001b[1me.g., \u001b[0m\u001b[1;32m'1'\u001b[0m\u001b[1m or \u001b[0m\u001b[1;32m'1,3'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Cloned Voice\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Cloned Voice\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> Comparison Figure\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m Comparison Figure\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Enter your choice(s)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEnter your choice(s)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Enter filename to save 'Cloned Voice'</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(saved_cloned_voice_output.wav)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEnter filename to save 'Cloned Voice'\u001b[0m \u001b[1;36m(saved_cloned_voice_output.wav)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ… <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Cloned Voice saved to d:\\CUDA_Experiments\\NLP\\Voice Processing\\clonevoicekeetan</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ… \u001b[1;32mCloned Voice saved to d:\\CUDA_Experiments\\NLP\\Voice Processing\\clonevoicekeetan\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Synthesize the same text in another language?</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[y/n]</span>: </pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mSynthesize the same text in another language?\u001b[0m \u001b[1;35m[y/n]\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Main Menu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â”‚ </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold\">Select an option</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">                                                                                                â”‚</span>\n",
       "<span style=\"color: #00ffff; text-decoration-color: #00ffff\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[96mâ•­â”€\u001b[0m\u001b[96mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[96m Main Menu \u001b[0m\u001b[96mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[96mâ”€â•®\u001b[0m\n",
       "\u001b[96mâ”‚\u001b[0m\u001b[96m \u001b[0m\u001b[1;96mSelect an option\u001b[0m\u001b[96m                                                                                               \u001b[0m\u001b[96m \u001b[0m\u001b[96mâ”‚\u001b[0m\n",
       "\u001b[96mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Choose an action:</span>\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Input Voice\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> Analyze Voice\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span> Text-to-Speech\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span> Exit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mChoose an action:\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Input Voice\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m Analyze Voice\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m Text-to-Speech\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m Exit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Enter your choice</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[1/2/3/4]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(1)</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEnter your choice\u001b[0m \u001b[1;35m[1/2/3/4]\u001b[0m \u001b[1;36m(1)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Exiting the NLP Suite. God Speed!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExiting the NLP Suite. God Speed!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Clear downloaded model cache?</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[y/n]</span>: </pre>\n"
      ],
      "text/plain": [
       "\u001b[1mClear downloaded model cache?\u001b[0m \u001b[1;35m[y/n]\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Voice NLP Suite (PRO Edition v6.0 - Advanced Workflow)\n",
    "Author: AI/ML Engineer (Gemini)\n",
    "Date: 2025-10-10\n",
    "Description: An expert-level suite for voice processing. This version introduces a new\n",
    "             workflow with file selection (including video), automatic translation for\n",
    "             synthesis, smart text chunking, and selective saving of artifacts.\n",
    "\"\"\"\n",
    "# --- Suppress all warnings for a clean, user-friendly output ---\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Core Libraries ---\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import speech_recognition as sr\n",
    "import librosa\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import re\n",
    "\n",
    "# --- Initialize UI Early to Catch Import Errors ---\n",
    "try:\n",
    "    from rich.console import Console\n",
    "    from rich.panel import Panel\n",
    "    from rich.prompt import Prompt, Confirm\n",
    "    from rich.table import Table\n",
    "    from rich.live import Live\n",
    "    RICH_UI_ENABLED = True\n",
    "    console = Console()\n",
    "except ImportError:\n",
    "    RICH_UI_ENABLED = False\n",
    "    class FallbackConsole:\n",
    "        def print(self, text): print(text)\n",
    "    console = FallbackConsole()\n",
    "\n",
    "# --- Optional/New Libraries ---\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    VISUALIZATION_ENABLED = True\n",
    "except ImportError:\n",
    "    VISUALIZATION_ENABLED = False\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from TTS.api import TTS\n",
    "    from TTS.tts.configs.xtts_config import XttsConfig\n",
    "    from TTS.tts.models.xtts import XttsAudioConfig, XttsArgs\n",
    "    from TTS.tts.configs.shared_configs import BaseDatasetConfig, BaseTTSConfig\n",
    "    import parselmouth\n",
    "    from parselmouth.praat import call as praat_call\n",
    "    import noisereduce as nr\n",
    "    from moviepy.editor import VideoFileClip\n",
    "    import translators as ts\n",
    "except ImportError as e:\n",
    "    console.print(f\"âŒ [bold red]A required library is missing. Please ensure 'moviepy' and 'translators' are installed ('pip install moviepy translators'). Error: {e}[/bold red]\")\n",
    "    exit()\n",
    "\n",
    "# --- Configuration ---\n",
    "SAMPLE_RATE = 22050\n",
    "INPUT_FILENAME = \"user_voice_input.wav\"\n",
    "CLEANED_FILENAME = \"cleaned_user_voice.wav\"\n",
    "CLONED_FILENAME = \"cloned_voice_output.wav\"\n",
    "FIGURE_FILENAME = \"voice_comparison.png\"\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    console.print(\"[bold bright_yellow]spaCy model 'en_core_web_sm' not found. Downloading...[/bold bright_yellow]\")\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "os.environ['COQUI_TOS_AGREED'] = '1'\n",
    "\n",
    "# --- 1. Voice Capture & Preprocessing ---\n",
    "def record_audio(duration=10):\n",
    "    # ... (code is unchanged)\n",
    "    console.print(f\"\\nðŸŽ™ï¸ [bold bright_cyan]Starting recording for {duration} seconds...[/bold bright_cyan]\")\n",
    "    recording = sd.rec(int(duration * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='int16')\n",
    "    if RICH_UI_ENABLED:\n",
    "        with Live(console=console, screen=False, auto_refresh=False) as live:\n",
    "            for i in range(duration, 0, -1):\n",
    "                live.update(f\"   [bold yellow]Recording... {i}s remaining[/bold yellow]\", refresh=True)\n",
    "                time.sleep(1)\n",
    "    else:\n",
    "        for i in range(duration, 0, -1):\n",
    "            print(f\"   Recording... {i}s remaining\", end='\\r')\n",
    "            time.sleep(1)\n",
    "        print()\n",
    "    sd.wait()\n",
    "    wav.write(INPUT_FILENAME, SAMPLE_RATE, recording)\n",
    "    console.print(f\"âœ… [bold green]Audio successfully saved as {INPUT_FILENAME}[/bold green]\")\n",
    "    return INPUT_FILENAME\n",
    "\n",
    "def select_and_process_file():\n",
    "    filepath = Prompt.ask(\"[bold]Please enter the path to your audio/video file[/bold]\")\n",
    "    if not os.path.exists(filepath):\n",
    "        console.print(f\"âŒ [bold red]File not found at '{filepath}'[/bold red]\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        console.print(f\"[italic]Processing file: {os.path.basename(filepath)}...[/italic]\")\n",
    "        _, ext = os.path.splitext(filepath)\n",
    "        if ext.lower() in ['.mp4', '.mov', '.avi', '.mkv']:\n",
    "            console.print(\"[italic]Video file detected. Extracting audio...[/italic]\")\n",
    "            video = VideoFileClip(filepath)\n",
    "            video.audio.write_audiofile(INPUT_FILENAME, samplerate=SAMPLE_RATE, logger=None)\n",
    "        else:\n",
    "            shutil.copy(filepath, INPUT_FILENAME)\n",
    "        \n",
    "        console.print(f\"âœ… [bold green]Audio successfully prepared as {INPUT_FILENAME}[/bold green]\")\n",
    "        return INPUT_FILENAME\n",
    "    except Exception as e:\n",
    "        console.print(f\"âŒ [bold red]Failed to process file. Error: {e}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "def run_preprocessing_menu(input_file, output_file):\n",
    "    # ... (code is unchanged)\n",
    "    console.print(Panel(\"[bold]ðŸ§¹ Optional Audio Preprocessing[/bold]\", style=\"bright_cyan\", title=\"Noise Reduction\"))\n",
    "    if not Confirm.ask(\"[bold]Do you want to apply noise reduction?[/bold]\"):\n",
    "        console.print(\"[bold yellow]Skipping noise reduction.[/bold yellow]\")\n",
    "        return input_file\n",
    "    prompt_text = (\"[bold]Choose a method:[/bold]\\n[1] Soft\\n[2] Moderate\\n[3] Robust\")\n",
    "    console.print(prompt_text)\n",
    "    choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=[\"1\", \"2\", \"3\"], default=\"2\")\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=SAMPLE_RATE)\n",
    "        if choice == '1':\n",
    "            reduced_noise = nr.reduce_noise(y=y, sr=sr, prop_decrease=0.8)\n",
    "        elif choice == '2':\n",
    "            non_silent = librosa.effects.split(y, top_db=30)\n",
    "            noise_clip = y[0:non_silent[0][0]] if len(non_silent) > 0 and non_silent[0][0] > 0 else y[0:int(sr*0.5)]\n",
    "            reduced_noise = nr.reduce_noise(y=y, y_noise=noise_clip, sr=sr, prop_decrease=0.95)\n",
    "        elif choice == '3':\n",
    "            reduced_noise, _ = librosa.effects.hpss(y)\n",
    "        sf.write(output_file, reduced_noise, sr)\n",
    "        console.print(f\"âœ… [bold green]Noise reduction complete.[/bold green]\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        console.print(f\"âŒ [bold red]Could not perform noise reduction: {e}.[/bold red]\")\n",
    "        return input_file\n",
    "\n",
    "# --- 2. Speech Recognition Engine ---\n",
    "def transcribe_audio(audio_file, model_size=\"base\", language=\"en\"):\n",
    "    # ... (code is unchanged)\n",
    "    console.print(f\"\\nðŸ§  [bold bright_cyan]Transcribing with Whisper ({model_size} model) for {language.upper()}[/bold bright_cyan]\")\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.AudioFile(audio_file) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "        text = recognizer.recognize_whisper(audio_data, model=model_size, language=language)\n",
    "        console.print(f\"ðŸ“ [bold green]Transcription:[/bold green] \\\"{text}\\\"\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        console.print(f\"âŒ [bold red]An error occurred during transcription: {e}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "# --- 3. Core Analysis Engine ---\n",
    "class VoiceAnalyzer:\n",
    "    # ... (code is unchanged, only analyze_linguistic is slightly adapted)\n",
    "    def __init__(self, audio_file, transcribed_text, language=\"en\"):\n",
    "        if not os.path.exists(audio_file): raise FileNotFoundError(f\"File not found: {audio_file}\")\n",
    "        self.audio_file = audio_file\n",
    "        self.text = transcribed_text or \"\"\n",
    "        self.language = language\n",
    "        self.y, self.sr = librosa.load(self.audio_file, sr=SAMPLE_RATE)\n",
    "        self.duration_seconds = librosa.get_duration(y=self.y, sr=self.sr)\n",
    "        self.sound = parselmouth.Sound(self.audio_file)\n",
    "\n",
    "    def analyze_acoustic(self):\n",
    "        try:\n",
    "            pitch = praat_call(self.sound, \"To Pitch\", 0.0, 75, 600)\n",
    "            mean_pitch = praat_call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "            formant = praat_call(self.sound, \"To Formant (burg)\", 0.0, 5, 5500, 0.025, 50)\n",
    "            f1_mean = praat_call(formant, \"Get mean\", 1, 0, 0, \"Hertz\")\n",
    "            f2_mean = praat_call(formant, \"Get mean\", 2, 0, 0, \"Hertz\")\n",
    "            rms = librosa.feature.rms(y=self.y)[0]\n",
    "            return {\"Pitch & Tone\": {\"Mean Pitch (Hz)\": f\"{mean_pitch:.2f}\"}, \"Formant Analysis\": {\"Mean F1 (Hz)\": f\"{f1_mean:.2f}\", \"Mean F2 (Hz)\": f\"{f2_mean:.2f}\"}, \"Energy & Loudness\": {\"Avg Intensity (RMS)\": f\"{np.mean(rms):.4f}\"}}\n",
    "        except Exception as e: return {\"Error\": f\"Analysis failed: {e}\"}\n",
    "\n",
    "    def analyze_linguistic(self):\n",
    "        if not self.text: return {\"Error\": \"No text to analyze.\"}\n",
    "        base_analysis = {\"Transcription\": {\"Full Text\": self.text}, \"Language Model\": {\"Acoustic Model\": \"Whisper\"}}\n",
    "        if self.language == \"en\":\n",
    "            doc = nlp(self.text)\n",
    "            blob = TextBlob(self.text)\n",
    "            base_analysis[\"Semantic Content\"] = {\"Keywords\": [chunk.text for chunk in doc.noun_chunks] or \"N/A\"}\n",
    "            base_analysis[\"Sentiment & Intent\"] = {\"Polarity\": f\"{blob.sentiment.polarity:.2f}\", \"Subjectivity\": f\"{blob.sentiment.subjectivity:.2f}\"}\n",
    "        else:\n",
    "            base_analysis[\"Note\"] = {\"Details\": \"Semantic/Sentiment analysis is optimized for English.\"}\n",
    "        return base_analysis\n",
    "\n",
    "    def analyze_emotional(self):\n",
    "        # ... (code is unchanged)\n",
    "        try:\n",
    "            jitter = \"N/A\"; shimmer = \"N/A\"; std_dev_pitch_str = \"N/A\"\n",
    "            try:\n",
    "                pitch = praat_call(self.sound, \"To Pitch\", 0.0, 75, 600)\n",
    "                std_dev_pitch = praat_call(pitch, \"Get standard deviation\", 0, 0, \"Hertz\")\n",
    "                std_dev_pitch_str = f\"{std_dev_pitch:.2f}\"\n",
    "            except Exception: pass\n",
    "            try:\n",
    "                point_process = praat_call(self.sound, \"To PointProcess (periodic, cc)\", 75, 600)\n",
    "                if praat_call(point_process, \"Get number of points\") > 1:\n",
    "                    jitter = f\"{praat_call(point_process, 'Get jitter (local)', 0, 0, 0.0001, 0.02, 1.3) * 100:.4f}%\"\n",
    "                    shimmer = f\"{praat_call(point_process, 'Get shimmer (local)', 0, 0, 0.0001, 0.02, 1.3, 1.6) * 100:.4f}%\"\n",
    "            except Exception: pass\n",
    "            return {\"Prosody\": {\"Pitch Variation (Hz)\": std_dev_pitch_str}, \"Vocal Stability\": {\"Jitter\": jitter, \"Shimmer\": shimmer}}\n",
    "        except Exception as e: return {\"Error\": f\"Analysis failed: {e}\"}\n",
    "\n",
    "    def analyze_biometric(self):\n",
    "        # ... (code is unchanged)\n",
    "        try:\n",
    "            pitch = praat_call(self.sound, \"To Pitch\", 0.0, 75, 600)\n",
    "            mean_pitch = praat_call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "            gender = \"Undetermined\"\n",
    "            if 85 < mean_pitch < 180: gender = \"Likely Male\"\n",
    "            elif 165 < mean_pitch < 255: gender = \"Likely Female\"\n",
    "            return {\"Identity Estimation\": {\"Estimated Gender\": f\"{gender}\"}, \"Speaker Adaptation\": {\"Method\": \"Zero-Shot Cloning\"}}\n",
    "        except Exception as e: return {\"Error\": f\"Analysis failed: {e}\"}\n",
    "\n",
    "    def analyze_technical(self):\n",
    "        # ... (code is unchanged)\n",
    "        if not self.text: return {\"Error\": \"No text to analyze.\"}\n",
    "        try: language = self.language.upper()\n",
    "        except: language = \"N/A\"\n",
    "        speaking_rate = (len(self.text.split()) / self.duration_seconds) * 60 if self.duration_seconds > 0 else 0\n",
    "        return {\"Speech Fluency\": {\"Speaking Rate (WPM)\": f\"{speaking_rate:.2f}\"}, \"Content\": {\"Detected Language\": language}}\n",
    "\n",
    "# --- 4. Quality & Visualization Modules ---\n",
    "def visualize_and_save_audio(original_file, cloned_file):\n",
    "    # ... (code is largely unchanged, just uses FIGURE_FILENAME)\n",
    "    if not VISUALIZATION_ENABLED: return False\n",
    "    console.print(\"\\nðŸ“Š [bold bright_cyan]Generating voice waveform comparison...[/bold bright_cyan]\")\n",
    "    try:\n",
    "        y_orig, _ = librosa.load(original_file, sr=SAMPLE_RATE)\n",
    "        y_cloned, _ = librosa.load(cloned_file, sr=SAMPLE_RATE)\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True, sharey=True)\n",
    "        fig.suptitle('Voice Waveform Comparison', fontsize=16, weight='bold')\n",
    "        librosa.display.waveshow(y_orig, sr=SAMPLE_RATE, ax=axes[0], color='royalblue'); axes[0].set_title(\"Original Voice\")\n",
    "        librosa.display.waveshow(y_cloned, sr=SAMPLE_RATE, ax=axes[1], color='darkorange'); axes[1].set_title(\"Synthesized Voice\")\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95]);\n",
    "        fig.savefig(FIGURE_FILENAME)\n",
    "        plt.show(block=True)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        console.print(f\"âŒ [bold red]Could not generate visualization. Error: {e}[/bold red]\")\n",
    "        return False\n",
    "\n",
    "# --- 5. Text-to-Speech Module ---\n",
    "def speak_text_with_cloning(text_to_speak, reference_audio_file, tts_model):\n",
    "    console.print(Panel(\"[bold]ðŸ—£ï¸ Advanced Text-to-Speech Engine[/bold]\", style=\"bright_cyan\", title=\"Cloning Voice\"))\n",
    "    \n",
    "    languages = {\"1\": (\"Hindi\", \"hi\"), \"2\": (\"English\", \"en\"), \"3\": (\"French\", \"fr\"), \"4\": (\"Russian\", \"ru\"), \"5\": (\"Chinese\", \"zh-cn\")}\n",
    "    \n",
    "    while True:\n",
    "        console.print(\"\\n[bold]Choose a language for synthesis:[/bold]\")\n",
    "        for key, (name, _) in languages.items(): console.print(f\"[{key}] {name}\")\n",
    "        lang_choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=languages.keys(), default=\"2\")\n",
    "        chosen_lang_name, chosen_lang_code = languages[lang_choice]\n",
    "\n",
    "        try:\n",
    "            console.print(f\"\\n[italic]Translating text to {chosen_lang_name}...[/italic]\")\n",
    "            translated_text = ts.translate_text(text_to_speak, to_language=chosen_lang_code)\n",
    "            console.print(f\"âœ… [bold green]Translated Text:[/bold green] \\\"{translated_text}\\\"\")\n",
    "            \n",
    "            console.print(f\"\\n[italic]Synthesizing '{chosen_lang_name}' speech...[/italic]\")\n",
    "            \n",
    "            # --- NEW ROBUST CHUNKING LOGIC ---\n",
    "            def create_chunks(text, limit=225):\n",
    "                chunks = []\n",
    "                # First, split by major sentence-ending punctuation\n",
    "                sentences = re.split('([.!?])', text)\n",
    "                # Combine sentences with their punctuation\n",
    "                if len(sentences) > 1:\n",
    "                    processed_sentences = [\"\".join(i) for i in zip(sentences[0::2], sentences[1::2])]\n",
    "                    if len(sentences) % 2 == 1:\n",
    "                        processed_sentences.append(sentences[-1])\n",
    "                else:\n",
    "                    processed_sentences = sentences\n",
    "\n",
    "                for sentence in processed_sentences:\n",
    "                    if len(sentence) <= limit:\n",
    "                        if sentence.strip(): chunks.append(sentence.strip())\n",
    "                    else:\n",
    "                        # Sentence is too long, split it further by words\n",
    "                        current_chunk = \"\"\n",
    "                        words = sentence.split(' ')\n",
    "                        for word in words:\n",
    "                            if len(current_chunk) + len(word) + 1 <= limit:\n",
    "                                current_chunk += word + \" \"\n",
    "                            else:\n",
    "                                if current_chunk.strip(): chunks.append(current_chunk.strip())\n",
    "                                current_chunk = word + \" \"\n",
    "                        if current_chunk.strip():\n",
    "                            chunks.append(current_chunk.strip())\n",
    "                return chunks\n",
    "\n",
    "            sentences = create_chunks(translated_text)\n",
    "            final_audio = []\n",
    "            temp_files = []\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                if not sentence: continue\n",
    "                temp_filename = f\"temp_chunk_{i}.wav\"\n",
    "                temp_files.append(temp_filename)\n",
    "                tts_model.tts_to_file(text=sentence, speaker_wav=reference_audio_file, language=chosen_lang_code, file_path=temp_filename)\n",
    "                y, sr = librosa.load(temp_filename, sr=SAMPLE_RATE)\n",
    "                final_audio.append(y)\n",
    "            \n",
    "            if not final_audio:\n",
    "                console.print(\"âŒ [bold red]Text was empty after processing. Cannot synthesize.[/bold red]\")\n",
    "                continue\n",
    "\n",
    "            concatenated_audio = np.concatenate(final_audio)\n",
    "            sf.write(CLONED_FILENAME, concatenated_audio, SAMPLE_RATE)\n",
    "\n",
    "            # Cleanup temp chunks\n",
    "            for f in temp_files: os.remove(f)\n",
    "\n",
    "            if os.path.exists(CLONED_FILENAME):\n",
    "                console.print(\"ðŸ”Š [bold]Playing cloned voice...[/bold]\")\n",
    "                sd.play(concatenated_audio, SAMPLE_RATE); sd.wait()\n",
    "                console.print(\"âœ… [bold green]Playback finished.[/bold green]\")\n",
    "                \n",
    "                was_viz_generated = visualize_and_save_audio(reference_audio_file, CLONED_FILENAME)\n",
    "                save_results_menu(did_clean=os.path.exists(CLEANED_FILENAME), did_clone=True, did_viz=was_viz_generated)\n",
    "\n",
    "        except Exception as e: \n",
    "            console.print(f\"âŒ [bold red]An error occurred during voice cloning: {e}[/bold red]\")\n",
    "        \n",
    "        if not Confirm.ask(\"\\n[bold]Synthesize the same text in another language?[/bold]\"):\n",
    "            break\n",
    "\n",
    "\n",
    "# --- 6. Main Application Logic ---\n",
    "def initialize_tts_model():\n",
    "    console.print(Panel(\"[bold]ðŸš€ Voice Cloning Model Setup[/bold]\", style=\"bright_cyan\"))\n",
    "    model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "    try:\n",
    "        console.print(f\"\\nâ³ [italic]Loading model '{model_name}' (this happens once)...[/italic]\")\n",
    "        if hasattr(torch, 'serialization') and hasattr(torch.serialization, 'safe_globals'):\n",
    "            with torch.serialization.safe_globals([XttsConfig, XttsAudioConfig, BaseDatasetConfig, XttsArgs, BaseTTSConfig]):\n",
    "                tts_model = TTS(model_name, progress_bar=True, gpu=False)\n",
    "        else:\n",
    "            tts_model = TTS(model_name, progress_bar=True, gpu=False)\n",
    "        console.print(\"âœ… [bold green]Voice cloning model ready.[/bold green]\"); return tts_model\n",
    "    except Exception as e: console.print(f\"âŒ [bold red]Could not load model. Error: {e}[/bold red]\"); return None\n",
    "\n",
    "def print_detailed_report(report):\n",
    "    # ... (code is unchanged)\n",
    "    METRIC_EXPLANATIONS = {\"Mean Fundamental Frequency (Hz)\": \"The average perceived pitch.\", \"Average Intensity (RMS)\": \"Corresponds to loudness.\", \"Polarity\": \"Sentiment from -1.0 (negative) to 1.0 (positive).\", \"Pitch Variation (Std Dev Hz)\": \"Higher values mean more expressive speech.\", \"Jitter\": \"Frequency variation, can relate to roughness.\", \"Shimmer\": \"Amplitude variation, can relate to breathiness.\", \"Speaking Rate (WPM)\": \"A measure of speech pace.\"}\n",
    "    console.print(Panel(\"[bold]Full Analysis Report[/bold]\", style=\"green\", border_style=\"green\"))\n",
    "    for category, analyses in report.items():\n",
    "        if not analyses: continue\n",
    "        table = Table(title=f\"[bold bright_cyan]{category}[/bold bright_cyan]\", show_header=False, box=None, padding=(0, 2))\n",
    "        table.add_column(\"Metric\", width=35); table.add_column(\"Value\", width=30); table.add_column(\"Explanation\", style=\"dim\")\n",
    "        if \"Error\" in analyses: table.add_row(\"[bold red]Error[/bold red]\", analyses[\"Error\"])\n",
    "        else:\n",
    "            for sub_category, metrics in analyses.items():\n",
    "                table.add_row(f\"[bold underline]{sub_category}[/bold underline]\", \"\")\n",
    "                for metric, value in metrics.items():\n",
    "                    explanation = METRIC_EXPLANATIONS.get(metric, \"\")\n",
    "                    table.add_row(f\"  {metric}\", str(value), explanation)\n",
    "        console.print(table)\n",
    "\n",
    "\n",
    "def save_results_menu(did_clean, did_clone, did_viz):\n",
    "    console.print(Panel(\"[bold]ðŸ’¾ Save Artifacts[/bold]\", style=\"bright_cyan\"))\n",
    "    choices = {}\n",
    "    if did_clean: choices[\"1\"] = (\"Cleaned Audio\", CLEANED_FILENAME)\n",
    "    if did_clone: choices[str(len(choices)+1)] = (\"Cloned Voice\", CLONED_FILENAME)\n",
    "    if did_viz: choices[str(len(choices)+1)] = (\"Comparison Figure\", FIGURE_FILENAME)\n",
    "\n",
    "    if not choices: return\n",
    "\n",
    "    console.print(\"[bold]Select which files you want to save (e.g., '1' or '1,3'):[/bold]\")\n",
    "    for key, (name, _) in choices.items():\n",
    "        console.print(f\"[{key}] {name}\")\n",
    "    \n",
    "    selections = Prompt.ask(\"[bold]Enter your choice(s)[/bold]\").replace(\" \", \"\").split(',')\n",
    "    for sel in selections:\n",
    "        if sel in choices:\n",
    "            name, temp_path = choices[sel]\n",
    "            save_path = Prompt.ask(f\"[bold]Enter filename to save '{name}'[/bold]\", default=f\"saved_{os.path.basename(temp_path)}\")\n",
    "            shutil.copy(temp_path, save_path)\n",
    "            console.print(f\"âœ… [bold green]{name} saved to {os.path.abspath(save_path)}[/bold green]\")\n",
    "\n",
    "def cleanup():\n",
    "    # ... (code is unchanged)\n",
    "    console.print(\"[bold green]Exiting the NLP Suite. God Speed![/bold green]\")\n",
    "    try:\n",
    "        sd.stop()\n",
    "        for f in [INPUT_FILENAME, CLEANED_FILENAME, CLONED_FILENAME, FIGURE_FILENAME]:\n",
    "            if os.path.exists(f): os.remove(f)\n",
    "        if Confirm.ask(\"[bold]Clear downloaded model cache?[/bold]\"):\n",
    "            tts_cache_path = os.path.join(os.path.expanduser(\"~\"), \".local\", \"share\", \"tts\")\n",
    "            if os.path.exists(tts_cache_path): shutil.rmtree(tts_cache_path)\n",
    "    except Exception: pass\n",
    "    finally: sys.exit(0)\n",
    "\n",
    "def main_menu():\n",
    "    console.print(Panel(\"[bold]Welcome to the Voice NLP Suite Pro v6.0[/bold]\\n[bright_cyan]Advanced Workflow Edition[/bright_cyan]\", style=\"green\", title=\"Voice NLP Suite\"))\n",
    "    tts_model = initialize_tts_model()\n",
    "    is_audio_ready = False; active_audio_file = None\n",
    "    \n",
    "    while True:\n",
    "        console.print(Panel(\"[bold]Select an option[/bold]\", style=\"bright_cyan\", title=\"Main Menu\"))\n",
    "        \n",
    "        analyze_option = \"[2] Analyze Voice\" if is_audio_ready else \"[dim][2] Analyze Voice (Input first)[/dim]\"\n",
    "        tts_option = \"[3] Text-to-Speech\" if is_audio_ready else \"[dim][3] Text-to-Speech (Input first)[/dim]\"\n",
    "        \n",
    "        prompt_text = f\"[bold]Choose an action:[/bold]\\n[1] Input Voice\\n{analyze_option}\\n{tts_option}\\n[4] Exit\"\n",
    "        console.print(prompt_text)\n",
    "        choice = Prompt.ask(\"[bold]Enter your choice[/bold]\", choices=[\"1\", \"2\", \"3\", \"4\"], default=\"1\")\n",
    "        \n",
    "        if choice == '1':\n",
    "            console.print(\"[bold]How would you like to provide audio?[/bold]\")\n",
    "            input_choice = Prompt.ask(\"[1] Record Voice\\n[2] Select a File\", choices=[\"1\", \"2\"], default=\"1\")\n",
    "            if input_choice == '1':\n",
    "                duration = int(Prompt.ask(\"[bold]Enter recording duration (5-15s recommended)[/bold]\", default=\"10\"))\n",
    "                record_audio(duration)\n",
    "                active_audio_file = INPUT_FILENAME\n",
    "            else:\n",
    "                active_audio_file = select_and_process_file()\n",
    "            \n",
    "            if active_audio_file:\n",
    "                is_audio_ready = True\n",
    "                if Confirm.ask(\"[bold]Do you want to apply noise reduction?[/bold]\"):\n",
    "                    active_audio_file = run_preprocessing_menu(active_audio_file, CLEANED_FILENAME)\n",
    "        \n",
    "        elif choice == '2':\n",
    "            if not is_audio_ready: console.print(\"ðŸ”´ [bold red]Please provide a voice input first.[/bold red]\"); continue\n",
    "            \n",
    "            console.print(\"\\n[bold]Choose the language of the audio:[/bold]\")\n",
    "            lang_map = {\"1\": (\"English\", \"en\"), \"2\": (\"Hindi\", \"hi\"), \"3\": (\"French\", \"fr\"), \"4\": (\"Russian\", \"ru\"), \"5\": (\"Chinese\", \"zh\")}\n",
    "            for k, (name, _) in lang_map.items(): console.print(f\"[{k}] {name}\")\n",
    "            lang_choice = Prompt.ask(\"[bold]Enter choice[/bold]\", choices=lang_map.keys(), default=\"1\")\n",
    "            _, transcription_lang_code = lang_map[lang_choice]\n",
    "            \n",
    "            transcribed_text = transcribe_audio(active_audio_file, language=transcription_lang_code)\n",
    "            if transcribed_text:\n",
    "                analyzer = VoiceAnalyzer(active_audio_file, transcribed_text, language=transcription_lang_code)\n",
    "                full_report = {\"ðŸŽ™ï¸ Acoustic Analysis\": analyzer.analyze_acoustic(), \"ðŸ§  Linguistic Analysis\": analyzer.analyze_linguistic(), \"ðŸ˜ƒ Emotional Analysis\": analyzer.analyze_emotional(), \"ðŸ§¬ Biometric Analysis\": analyzer.analyze_biometric(), \"ðŸ› ï¸ Technical Analysis\": analyzer.analyze_technical()}\n",
    "                print_detailed_report(full_report)\n",
    "                save_results_menu(did_clean=(active_audio_file == CLEANED_FILENAME), did_clone=False, did_viz=False)\n",
    "\n",
    "        elif choice == '3':\n",
    "            if not is_audio_ready: console.print(\"ðŸ”´ [bold red]Please provide a voice input first.[/bold red]\"); continue\n",
    "            if not tts_model: console.print(\"ðŸ”´ [bold red]TTS is disabled.[/bold red]\"); continue\n",
    "            text_to_speak = Prompt.ask(\"[bold]Enter the text to synthesize[/bold]\")\n",
    "            if text_to_speak: speak_text_with_cloning(text_to_speak, active_audio_file, tts_model)\n",
    "        \n",
    "        elif choice == '4':\n",
    "            cleanup()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_menu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14fdd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_suite_voice (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
